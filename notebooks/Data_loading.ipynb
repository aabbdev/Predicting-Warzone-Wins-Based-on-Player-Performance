{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "The scraped data was saved as dictionaries and exported as .pkl files. The data files can be found within the data folder. Each file is labelled with the platform and features indicating what data is saved in each file.\n",
    "\n",
    "Goal: Load all the data files into one master data frame.\n",
    "\n",
    "Refer to https://stackoverflow.com/questions/30898038/python-run-script-on-multiple-files for running script on multiple files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thought that crossed my mind:\n",
    "\n",
    "**How does pandas deal with missing attributes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating fake player data with missing values for players sneef and sreef\n",
    "players = {'smeef':{'wins':22, 'mp':123, 'kd': 0.23},\n",
    "          'sneef': {'wins': 34, 'mp': 129},\n",
    "          'sreef': {'wins':44, 'kd':0.24},\n",
    "          'schniegel': {'wins':43, 'mp':555, 'kd':1.23}\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wins</th>\n",
       "      <th>mp</th>\n",
       "      <th>kd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>smeef</td>\n",
       "      <td>22.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sneef</td>\n",
       "      <td>34.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sreef</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>schniegel</td>\n",
       "      <td>43.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           wins     mp    kd\n",
       "smeef      22.0  123.0  0.23\n",
       "sneef      34.0  129.0   NaN\n",
       "sreef      44.0    NaN  0.24\n",
       "schniegel  43.0  555.0  1.23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(players).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so the missing attributes are returned as NaNs. Fine, we can later impute these values. The implication on data loading means we can simply merge all the data dictionaries without worrying about missing values initially - will be dealt with once loaded into panas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps to Group data into one dictionary (later to be loaded into a pandas dataframe)\n",
    "\n",
    "1. Initialize an empty dictionary (call it df_dict for example)\n",
    "2. Load in data file (which is in the form of a dict)\n",
    "3. Add player data loaded from step 2 into df_dict\n",
    "    - if first file, then simply add all the players\n",
    "    - if a subsequent file, append player data; if player does not exist in df_dict, add them as a new player\n",
    "4. Repeat steps 2-3 for all data files\n",
    "5. Once all data is added to df_dict, load it into pandas dataframe using from_dict() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: scraped data from 2 different websites.\n",
    "- files starting with 'all' were scraped from **cdst**\n",
    "- files starting with 'psn', 'xbl', or 'battlenet' were scraped from **cdtr**\n",
    "\n",
    "The data has been standardized during scraping such that each player's is saved in a dictionary within a dictionary. For clarity, each player in the main dictionary is in the form of:\n",
    "\n",
    "{'random_player' : {platform : 'psn', stat : 23), 'next_player':{...}, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: initialize main dictionary\n",
    "df_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Load in data\n",
    "\n",
    "#example using psn Kills from cdtr\n",
    "with open('../data/psn_Kills.pkl', 'rb') as file:\n",
    "    psn_Kills = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "831249"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many players?\n",
    "len(psn_Kills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 3: add player data to df_dict\n",
    "\n",
    "#although this is the first time we are adding data to df_dict, \n",
    "#let's pretend we are not sure if df_dict has data already\n",
    "\n",
    "#we can see if df_dict is not empty using the bool() function\n",
    "bool(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "831249"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if df_dict is empty, add data\n",
    "if bool(df_dict) == False:\n",
    "    df_dict = psn_Kills.copy()\n",
    "len(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Let's add data from a new file\n",
    "\n",
    "#using psn Wins\n",
    "with open('../data/psn_Wins.pkl', 'rb') as file:\n",
    "    psn_Wins = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 635033/635033 [00:00<00:00, 803784.70it/s]\n"
     ]
    }
   ],
   "source": [
    "#we know df_dict has player data now so we need to match players by\n",
    "#their name and platform\n",
    "\n",
    "#for each player in the psn_Wins dict...\n",
    "for player, stat in tqdm(psn_Wins.items()):\n",
    "    #...if player is in df_dict and platforms are the same (now dealing with only psn but will be needed later)\n",
    "    if player in df_dict and df_dict[player]['platform'] == psn_Wins[player]['platform']:\n",
    "        #add wins to df_dict\n",
    "        df_dict[player]['wins'] = stat['wins']\n",
    "    #...but if not in df_dict, add them in as a new player (note that this will lead in missing values which later need to be imputed)\n",
    "    else:\n",
    "        df_dict[player] = {'platform': stat['platform'], 'wins': stat['wins']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'platform': 'psn', 'Kills': '26,580', 'wins': 1225}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if kills were added to an example player\n",
    "df_dict['TTV-Scop3s_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Both kills and wins are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936521"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we also had a lot of new players added\n",
    "len(df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next Steps\n",
    "\n",
    "- check how to add cdst data in df_dict\n",
    "- build script to go through each pkl file and add it to a master dictionary (e.g. df_dict)\n",
    "- load dictionary containing all the player data into a pandas dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
